{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name1                     Name2                   R             G/O  \\\n",
      "0    Judge  Ella\\rBullock-\\rpapa (N)                   1               G   \n",
      "1    Judge  Ella\\rBullock-\\rpapa (N)                   2               O   \n",
      "2    Judge  Ella\\rBullock-\\rpapa (N)                   3               O   \n",
      "3    Judge  Ella\\rBullock-\\rpapa (N)                   4               G   \n",
      "4    Judge  Ella\\rBullock-\\rpapa (N)                   5               G   \n",
      "..     ...                       ...                 ...             ...   \n",
      "351    NaN                       NaN                   2               O   \n",
      "352    NaN                       NaN                   3               G   \n",
      "353    NaN                       NaN                   4               O   \n",
      "354    NaN                       NaN                   5               O   \n",
      "355    NaN                       NaN  Tournament Totals:  (140.00,16.00)   \n",
      "\n",
      "                W/L                    Opponent  \\\n",
      "0                 L             girls next door   \n",
      "1                 W                      NYU CS   \n",
      "2                 W  Nacho Average\\rMissourians   \n",
      "3                 L         quaker spice\\rgirls   \n",
      "4                 L                  Casual Sex   \n",
      "..              ...                         ...   \n",
      "351               L                 Stanford CT   \n",
      "352               W      U Massdebate\\rToo Much   \n",
      "353               L             girls next door   \n",
      "354               L                 Stanford CK   \n",
      "355  (146.00,10.00)              (286.00,26.00)   \n",
      "\n",
      "                         Unnamed: 4                        Person1  \\\n",
      "0                               NaN  Ryan Gumlia -\\rShyla\\rSummers   \n",
      "1                               NaN                    Teddy Tawil   \n",
      "2                               NaN              Chris\\rVanderpool   \n",
      "3                               NaN               Reed\\rEasterling   \n",
      "4                               NaN                    Ben Daniels   \n",
      "..                              ...                            ...   \n",
      "351        Aidan Healy -\\rJaimy Kim                    (27.0, 4.0)   \n",
      "352  Reed Easterling\\r- Ryan Gumlia                    (27.0, 3.0)   \n",
      "353                    Maddie Nagle                    (28.0, 4.0)   \n",
      "354                    Aryan Sehgal                    (28.0, 2.0)   \n",
      "355                             NaN                            NaN   \n",
      "\n",
      "         Person2 Stone Yang\\r(N)          Total  \n",
      "0    (29.0, 2.0)     (27.0, 4.0)    (56.0, 6.0)  \n",
      "1    (29.0, 2.0)     (31.0, 1.0)   (116.0, 9.0)  \n",
      "2    (30.0, 1.0)     (29.0, 2.0)  (175.0, 12.0)  \n",
      "3    (25.0, 4.0)     (26.0, 3.0)  (226.0, 19.0)  \n",
      "4    (29.0, 4.0)     (30.0, 2.0)  (285.0, 25.0)  \n",
      "..           ...             ...            ...  \n",
      "351  (29.0, 2.0)   (118.0, 10.0)            NaN  \n",
      "352  (28.0, 1.0)   (173.0, 14.0)            NaN  \n",
      "353  (31.0, 2.0)   (232.0, 20.0)            NaN  \n",
      "354  (26.0, 4.0)   (286.0, 26.0)            NaN  \n",
      "355          NaN             NaN            NaN  \n",
      "\n",
      "[356 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tabula\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Set the path to the directory containing the PDFs\n",
    "pdf_directory = './rawtabcards/'\n",
    "\n",
    "\n",
    "                         \n",
    "# Extract tables from the PDF file\n",
    "pdf_path = pdf_directory = './rawtabcards/Yale APDA 2023 Tab Cards.pdf'\n",
    "tables = tabula.read_pdf(pdf_path, pages='all', output_format='dataframe', multiple_tables = True, lattice = True, guess = False,)\n",
    "##initialize first dataframe\n",
    "df = tables[0]\n",
    "name1 = df.columns[5]\n",
    "name2 = df.columns[6]\n",
    "\n",
    "##names1 = df.iloc[6::6, 5]\n",
    "##names2 = df.iloc[6::6, 6]\n",
    "##print(names1)\n",
    "##print(names2)\n",
    "\n",
    "new_names = {df.columns[5]: 'Person1', df.columns[6]: 'Person2'}\n",
    "df = df.rename(columns=new_names)\n",
    "##team = name1 + \", \" + name2\n",
    "# insert a new column at the beginning of the DataFrame\n",
    "new_column = pd.Series([name1 for i in range(5)], name='Name1')\n",
    "df.insert(0, 'Name1', new_column)\n",
    "\n",
    "new_column = pd.Series([name2 for i in range(5)], name='Name2')\n",
    "df.insert(1, 'Name2', new_column)\n",
    "\n",
    "print(df)\n",
    "# Unused metric for now\n",
    "mask = ~df['R'].str.startswith('Tournament Totals:')\n",
    "df = df.loc[mask]\n",
    "# Filter rows that start with \"R\" to get participant names\n",
    "filtered_df = df[df['R'].str.startswith('R')]\n",
    "names1 = filtered_df['Person1']\n",
    "names2 = filtered_df['Person2']\n",
    "\n",
    "\n",
    "##Remove dummy header columns\n",
    "mask = ~df['R'].str.startswith('R')\n",
    "df = df.loc[mask]\n",
    "\n",
    "\n",
    "##Insertion of both names\n",
    "i = 0\n",
    "j = -1\n",
    "while True:\n",
    "    if i % 5 == 0:\n",
    "        j+=7\n",
    "    try:\n",
    "        df.iloc[i+5, df.columns.get_loc('Name1')] = names1[j]\n",
    "        df.iloc[i+5, df.columns.get_loc('Name2')] = names2[j]\n",
    "    except KeyError:\n",
    "        break\n",
    "    i+=1\n",
    "\n",
    "\n",
    "    \n",
    "output_path = \"./file.csv\"\n",
    "df.to_csv(output_path, index=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bing Fall 2022 Tab Cards.pdf\n",
      "BroAmsTabCards.pdf\n",
      "broccoli.nu-tab.com.pdf\n"
     ]
    },
    {
     "ename": "CSVParseError",
     "evalue": "Error failed to create DataFrame with different column tables.\nTry to set `multiple_tables=True`or set `names` option for `pandas_options`. \n, caused by ParserError('Error tokenizing data. C error: Expected 8 fields in line 8, saw 9\\n')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tabula\\io.py\u001b[0m in \u001b[0;36mread_pdf\u001b[1;34m(input_path, output_format, encoding, java_options, pandas_options, multiple_tables, user_agent, use_raw_url, pages, guess, area, relative_area, lattice, stream, password, silent, columns, relative_columns, format, batch, output_path, options)\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpandas_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    451\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParserError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1253\u001b[1;33m                 \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1254\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 8 fields in line 8, saw 9\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCSVParseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4528\\1125508028.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# Extract tables from the PDF file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mpdf_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdf_directory\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mtables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtabula\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dataframe'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultiple_tables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;31m##initialize first dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tabula\\io.py\u001b[0m in \u001b[0;36mread_pdf\u001b[1;34m(input_path, output_format, encoding, java_options, pandas_options, multiple_tables, user_agent, use_raw_url, pages, guess, area, relative_area, lattice, stream, password, silent, columns, relative_columns, format, batch, output_path, options)\u001b[0m\n\u001b[0;32m    456\u001b[0m             )\n\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mCSVParseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCSVParseError\u001b[0m: Error failed to create DataFrame with different column tables.\nTry to set `multiple_tables=True`or set `names` option for `pandas_options`. \n, caused by ParserError('Error tokenizing data. C error: Expected 8 fields in line 8, saw 9\\n')"
     ]
    }
   ],
   "source": [
    "pdf_directory = './rawtabcards/'\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(pdf_directory):\n",
    "    print(filename)\n",
    "    if filename == 'BroAmsTabCards.pdf':\n",
    "        continue\n",
    "    if filename.endswith('.pdf'):\n",
    "\n",
    "        # Extract tables from the PDF file\n",
    "        pdf_path = pdf_directory + filename\n",
    "        tables = tabula.read_pdf(pdf_path, pages='all', output_format='dataframe', multiple_tables = True)\n",
    "        ##initialize first dataframe\n",
    "        df = tables[0]\n",
    "        name1 = df.columns[5]\n",
    "        name2 = df.columns[6]\n",
    "\n",
    "        ##names1 = df.iloc[6::6, 5]\n",
    "        ##names2 = df.iloc[6::6, 6]\n",
    "        ##print(names1)\n",
    "        ##print(names2)\n",
    "\n",
    "        new_names = {df.columns[5]: 'Person1', df.columns[6]: 'Person2'}\n",
    "        df = df.rename(columns=new_names)\n",
    "        ##team = name1 + \", \" + name2\n",
    "        # insert a new column at the beginning of the DataFrame\n",
    "        new_column = pd.Series([name1 for i in range(5)], name='Name1')\n",
    "        df.insert(0, 'Name1', new_column)\n",
    "\n",
    "        new_column = pd.Series([name2 for i in range(5)], name='Name2')\n",
    "        df.insert(1, 'Name2', new_column)\n",
    "\n",
    "        # Unused metric for now\n",
    "        mask = ~df['R'].str.startswith('Tournament Totals:')\n",
    "        df = df.loc[mask]\n",
    "        # Filter rows that start with \"R\" to get participant names\n",
    "        filtered_df = df[df['R'].str.startswith('R')]\n",
    "        names1 = filtered_df['Person1']\n",
    "        names2 = filtered_df['Person2']\n",
    "\n",
    "\n",
    "        ##Remove dummy header columns\n",
    "        mask = ~df['R'].str.startswith('R')\n",
    "        df = df.loc[mask]\n",
    "\n",
    "        ##Insertion of both names\n",
    "        i = 0\n",
    "        j = -1\n",
    "        while True:\n",
    "            if i % 5 == 0:\n",
    "                j+=7\n",
    "            try:\n",
    "                df.iloc[i+5, df.columns.get_loc('Name1')] = names1[j]\n",
    "                df.iloc[i+5, df.columns.get_loc('Name2')] = names2[j]\n",
    "            except KeyError:\n",
    "                break\n",
    "            i+=1\n",
    "\n",
    "\n",
    "\n",
    "        output_path = \"./file.csv\"\n",
    "        df.to_csv(output_path, index=True)\n",
    "    \n",
    "'''\n",
    "# Loop through remaining tables and concatenate without headers\n",
    "for table in tables[1:]:\n",
    "\n",
    "    # Concatenate the dataframes into a single dataframe\n",
    "    ##df = pd.concat(tables, ignore_index=True)\n",
    "\n",
    "    df = table\n",
    "    name1 = df.columns[5]\n",
    "    name2 = df.columns[6]\n",
    "\n",
    "\n",
    "    team = name1 + \", \" + name2\n",
    "\n",
    "    # insert a new column at the beginning of the DataFrame\n",
    "    new_column = pd.Series([team for i in range(5)], name='Names')\n",
    "    df.insert(0, 'Names', new_column)\n",
    "        \n",
    "    # Remove rows that start with a specific name\n",
    "    mask = ~df['R'].str.startswith('Tournament Totals:')\n",
    "    df = df.loc[mask]\n",
    "    \n",
    "    ##Remove headers\n",
    "    df.columns = range(df.shape[1])\n",
    "    print(df)\n",
    "    df_concat = pd.concat([df_concat, df], axis=1)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
